# ðŸ§  Modular Anomaly Detection Framework (MNIST Benchmark)

## Overview

This repository implements a **modular, end-to-end anomaly detection framework** using deep autoencoders, with a focus on **reconstruction-based anomaly detection and localization**.

The project is designed as a **research-ready framework**, not a single experiment.  
All componentsâ€”datasets, corruptions, models, metrics, and visualizationsâ€”are implemented in a reusable and extensible manner.

The MNIST dataset is used as a **controlled benchmark** to study:
- What constitutes an anomaly
- How reconstruction error separates normal vs anomalous samples
- How architectural choices (e.g. bottleneck size) affect detection performance
- How anomalies can be **localized spatially** via error heatmaps

---

## Key Contributions

- âœ… End-to-end anomaly detection pipeline  
- âœ… Modular corruption (anomaly) generators  
- âœ… Autoencoder-based reconstruction model  
- âœ… ROCâ€“AUC based evaluation  
- âœ… Pixel-level anomaly localization via error heatmaps  
- âœ… Robustness studies:
  - Bottleneck size vs performance  
  - Contamination robustness  
  - Difficulty (noise strength) scaling  
- âœ… Script-based reproducibility (no notebook dependency)

---
## Repository Structure
```text
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ autoencoder.py        # Autoencoder architecture
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ corruptions.py        # Anomaly generation functions
â”‚   â”‚   â”œâ”€â”€ metrics.py            # Evaluation metrics (ROC, AUC)
â”‚   â”‚   â””â”€â”€ heatmaps.py           # Error heatmap & localization utilities
â”‚   â””â”€â”€ datasets/
â”‚       â””â”€â”€ mnist.py              # MNIST loading utilities
â”‚
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ baseline_mnist.py         # End-to-end experiment script
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_anomaly_examples.ipynb
â”‚   â””â”€â”€ 03_autoencoder_baseline.ipynb
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ anomalies/                # Heatmaps & localization outputs
â”‚   â”œâ”€â”€ plots/                    # ROC, robustness, ablation plots
â”‚   â””â”€â”€ dataset_stats.json
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---
## Methodology

### 1. Problem Definition

An anomaly is defined as an input that **deviates from the normal data distribution** and is therefore poorly reconstructed by a model trained only on normal data.

---

### 2. Model: Autoencoder

A convolutional autoencoder is trained to reconstruct MNIST digits.

- Encoder compresses the image into a low-dimensional bottleneck  
- Decoder reconstructs the image from this representation  
- Reconstruction error serves as the anomaly score  

---

### 3. Anomaly Generation

Anomalies are synthetically generated using controlled corruptions:

- **Pixel Dropout** â€“ random pixel masking  
- **Gaussian Noise** â€“ additive noise with adjustable variance  
- **Stripe Corruption** â€“ full row/column corruption  
- **Random Patch Occlusion** â€“ localized missing regions  

These corruptions allow controlled study of anomaly difficulty.

---

### 4. Detection & Evaluation

- Reconstruction error is computed per image  
- ROC curves are generated using normal vs anomalous samples  
- Area Under Curve (AUC) is used as the primary metric  

---

### 5. Localization

Pixel-wise reconstruction error maps are visualized as heatmaps to **localize anomalous regions** within images.

---

### 6. Robustness Experiments

The framework includes systematic studies of:

- **Bottleneck size vs AUC**  
- **Training contamination vs detection performance**  
- **Anomaly difficulty scaling**  

---

## Results Summary

- Near-perfect separation achieved for strong anomalies (AUC â‰ˆ 1.0)  
- Performance degrades gracefully with increasing anomaly difficulty  
- Smaller bottlenecks encourage better anomaly sensitivity  
- Error heatmaps accurately localize corrupted regions  

---

## How to Run

### 1. Setup Environment

```bash
pip install -r requirements.txt
```
### 2. Run Full Experiment

```bash
python experiments/baseline_mnist.py
```
This will automatically:

- Train the autoencoder  
- Generate anomalies  
- Compute ROC & AUC  
- Save plots and heatmaps to `results/`  

---

## Design Philosophy

- **Modularity** over monolithic notebooks  
- **Reproducibility** over ad-hoc experimentation  
- **Clarity** over excessive abstraction  
- **Research-first**, framework-second  

---

## Future Extensions

This framework is intentionally designed to support:

- Additional datasets (medical imaging, scientific data)  
- Alternative models (VAEs, diffusion-based methods)  
- Semi-supervised and weakly-supervised anomaly detection  
- Benchmarking across domains  

---

## Author

**Ajay Bandiwaddar**  
(GSoC 2026 Applicant)

---

## License

This project is released for research and educational use.

---